@article{cadimaRelationshipsUncentredColumnCentred2009,
  entrysubtype = {magazine},
  title = {On {{Relationships Between Uncentred And Column-Centred Principal Component Analysis}}},
  author = {Cadima, Jorge and Jolliffe, Ian T.},
  date = {2009},
  journaltitle = {Pakistan Journal of Statistics},
  volume = {25},
  number = {4},
  pages = {473--504},
  url = {https://www.researchgate.net/publication/255644479_On_Relationships_Between_Uncentred_And_Column-Centred_Principal_Component_Analysis},
  urldate = {2025-03-20},
  abstract = {Access 135+ million publications and connect with 20+ million researchers. Join for free and gain visibility by uploading your research.},
  langid = {english}
}

@misc{chenLecture5Singular2020,
  title = {Lecture 5: {{Singular Value Decomposition}} ({{SVD}})},
  author = {Chen, Guangliang},
  date = {2020},
  url = {https://www.sjsu.edu/faculty/guangliang.chen/Math253S20/lec5svd.pdf},
  urldate = {2025-01-20},
  langid = {english},
  organization = {San José State University},
  file = {C:\Users\Noah\Zotero\storage\RSJK6SQY\Chen - Lecture 5 Singular Value Decomposition (SVD).pdf}
}

@online{cheruvilthomasAnswerWhyDoes2013,
  title = {Answer to "{{Why}} Does the Rank of the Design Matrix {{X}} Equal the Rank of {{X}}'{{X}}?"},
  shorttitle = {Answer to "{{Why}} Does the Rank of the Design Matrix {{X}} Equal the Rank of {{X}}'{{X}}?},
  author = {Cheruvil Thomas, Vinu},
  date = {2013-02-13},
  url = {https://stats.stackexchange.com/a/49897},
  urldate = {2025-03-22},
  organization = {Cross Validated},
  file = {C:\Users\Noah\Zotero\storage\PYC5J65Q\why-does-the-rank-of-the-design-matrix-x-equal-the-rank-of-xx.html}
}

@inproceedings{cremonesiPerformanceRecommenderAlgorithms2010,
  title = {Performance of {{Recommender Algorithms}} on {{Top-N Recommendation Tasks}}},
  booktitle = {Proceedings of the Fourth {{ACM}} Conference on {{Recommender}} Systems},
  author = {Cremonesi, Paolo and Koren, Yehuda and Turrin, Roberto},
  date = {2010-09-26},
  series = {{{RecSys}} '10},
  pages = {39--46},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1864708.1864721},
  url = {https://dl.acm.org/doi/10.1145/1864708.1864721},
  urldate = {2025-03-13},
  abstract = {In many commercial systems, the 'best bet' recommendations are shown, but the predicted rating values are not. This is usually referred to as a top-N recommendation task, where the goal of the recommender system is to find a few specific items which are supposed to be most appealing to the user. Common methodologies based on error metrics (such as RMSE) are not a natural fit for evaluating the top-N recommendation task. Rather, top-N performance can be directly measured by alternative methodologies based on accuracy metrics (such as precision/recall).An extensive evaluation of several state-of-the art recommender algorithms suggests that algorithms optimized for minimizing RMSE do not necessarily perform as expected in terms of top-N recommendation task. Results show that improvements in RMSE often do not translate into accuracy improvements. In particular, a naive non-personalized algorithm can outperform some common recommendation approaches and almost match the accuracy of sophisticated algorithms. Another finding is that the very few top popular items can skew the top-N performance. The analysis points out that when evaluating a recommender algorithm on the top-N recommendation task, the test set should be chosen carefully in order to not bias accuracy metrics towards non-personalized solutions. Finally, we offer practitioners new variants of two collaborative filtering algorithms that, regardless of their RMSE, significantly outperform other recommender algorithms in pursuing the top-N recommendation task, with offering additional practical advantages. This comes at surprise given the simplicity of these two methods.},
  isbn = {978-1-60558-906-0},
  file = {C:\Users\Noah\Zotero\storage\L6RWTI2T\Cremonesi et al. - 2010 - Performance of recommender algorithms on top-n recommendation tasks.pdf}
}

@book{deitmarAnalysis2021,
  title = {Analysis},
  author = {Deitmar, Anton},
  date = {2021},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-62858-4},
  url = {http://link.springer.com/10.1007/978-3-662-62858-4},
  urldate = {2025-03-08},
  isbn = {978-3-662-62857-7 978-3-662-62858-4},
  langid = {ngerman},
  keywords = {Analysis 1-3,Differentialformen,Differentialrechnung,Grundvorlesung Analysis,Integralrechnung,Maßtheorie},
  file = {C:\Users\Noah\Zotero\storage\MKKZG3DJ\Deitmar - 2021 - Analysis.pdf}
}

@article{diaz-moralesDeepLearningCombined2024,
  title = {Deep Learning Combined with Singular Value Decomposition to Reconstruct Databases in Fluid Dynamics},
  author = {Díaz-Morales, P. and Corrochano, A. and López-Martín, M. and Le Clainche, S.},
  date = {2024-03-15},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {238},
  number = {B},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2023.121924},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417423024260},
  urldate = {2025-03-26},
  abstract = {Fluid dynamics problems are characterized by being multidimensional and nonlinear. Therefore, experiments and numerical simulations are complex and time-consuming. Motivated by this, the need arises to find new techniques to obtain data in a simpler way and in less time. In this article, we present a novel methodology based on physical principles to reconstruct databases with three, four and five dimensions, from sparse databases formed by sensor measurements. The methodology consists of combining Single Value Decomposition (SVD), which can extract the main flow dynamics, with neural networks. The neural network used is characterized by a simple architecture based on combining two autoencoders that work in parallel and are joined in the last layer. This new algorithm has been proved with three databases with different dimensions and complexities: in an Atmospheric Boundary Layer (ABL) with a turbulence model and in the flow past a two- and a three-dimensional cylinder. By applying this methodology, it has been achieved to reconstruct databases of different dimensions obtaining errors of the same order as those obtained in simulations. Summarizing, this work proposes a new hybrid physics-based machine learning model with a simple, robust and generalizable architecture, which allows reconstructing databases from very few sensors and with a very low computational cost.},
  keywords = {Complex flows,Data reconstruction,Deep learning,Fluid dynamics,PDE surrogates,Singular value decomposition}
}

@misc{frazzoliDynamicSystemsControl2011,
  title = {Dynamic {{Systems And Control}}. {{Lecture}} 4: {{Singular Values}}},
  author = {Frazzoli, Emilio},
  date = {2011},
  url = {https://ocw.mit.edu/courses/6-241j-dynamic-systems-and-control-spring-2011/resources/mit6_241js11_lec04/},
  urldate = {2025-03-09},
  abstract = {This resource contains information related to singular values.},
  langid = {english},
  organization = {Massachusetts Institute of Technology},
  file = {C:\Users\Noah\Zotero\storage\585JWH49\mit6_241js11_lec04.html}
}

@article{harperMovieLensDatasetsHistory2015,
  title = {The {{MovieLens Datasets}}: {{History}} and {{Context}}},
  shorttitle = {The {{MovieLens Datasets}}},
  author = {Harper, F. Maxwell and Konstan, Joseph A.},
  date = {2015-12-22},
  journaltitle = {ACM Trans. Interact. Intell. Syst.},
  volume = {5},
  number = {4},
  pages = {19:1--19:19},
  issn = {2160-6455},
  doi = {10.1145/2827872},
  url = {https://dl.acm.org/doi/10.1145/2827872},
  urldate = {2025-03-20},
  abstract = {The MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research.},
  file = {C:\Users\Noah\Zotero\storage\FMFJ4GSF\Harper und Konstan - 2015 - The MovieLens Datasets History and Context.pdf}
}

@misc{hsuMachineLearningTheory2016,
  title = {Machine Learning Theory. {{COMS}} 4772. {{Topic}} 5: {{Principal}} Component Analysis.},
  author = {Hsu, Daniel},
  date = {2016},
  url = {https://www.cs.columbia.edu/~djhsu/AML/lectures/notes-pca.pdf},
  urldate = {2025-02-25},
  organization = {Columbia University},
  file = {C:\Users\Noah\Zotero\storage\DYNE85YS\notes-pca.pdf}
}

@book{johnstonAdvancedLinearMatrix2021,
  title = {Advanced {{Linear}} and {{Matrix Algebra}}},
  author = {Johnston, Nathaniel},
  date = {2021},
  publisher = {Springer},
  location = {Cham},
  doi = {10.1007/978-3-030-52815-7},
  url = {https://link.springer.com/10.1007/978-3-030-52815-7},
  urldate = {2025-01-25},
  isbn = {978-3-030-52814-0 978-3-030-52815-7},
  langid = {english},
  keywords = {Cholesky decomposition,Isomorphism linear algebra,Jordan decomposition,Kronecker product,Linear algebra textbook,Linear transformation matrix,Matrix algebra textbook,Matrix algebra vs linear algebra,Matrix decomposition,Multilinear transformations,Multilinearity,Projections linear algebra,QR decomposition,Schur triangularization,Second course in linear algebra textbook,Singular value decomposition,Spectral decomposition,Tensor products textbook,Vector spaces}
}

@book{karpfingerLineareAlgebra2020,
  title = {Lineare Algebra},
  author = {Karpfinger, Christian and Stachel, Hellmuth},
  date = {2020},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-61340-5},
  url = {http://link.springer.com/10.1007/978-3-662-61340-5},
  urldate = {2024-12-26},
  isbn = {978-3-662-61339-9 978-3-662-61340-5},
  langid = {ngerman},
  keywords = {Lehrbuch,lineare Abbildungen,Matrizen,Prüfungsvorbereitung,Vektoren,Vektorräume},
  file = {C:\Users\Noah\Zotero\storage\Z2YFQKR2\Karpfinger und Stachel - 2020 - Lineare Algebra.pdf}
}

@misc{karypisApplicationDimensionalityReduction2000,
  title = {Application of {{Dimensionality Reduction}} in {{Recommender System}} - {{A Case Study}}},
  author = {Karypis, George and Sarwar, Badrul M. and Konstan, Joseph A. and Riedl, John T.},
  date = {2000},
  url = {https://conservancy.umn.edu/server/api/core/bitstreams/45af5e1e-3c87-480c-a817-28f886ddd796/content},
  urldate = {2025-03-07},
  abstract = {We investigate the use of dimensionality reduction to improve performance for a new class of data analysis software called \&quot;recommender systems\&quot;. Recommender systems apply knowledge discovery techniques to the problem of making product},
  langid = {english},
  organization = {University of Minnesota},
  file = {C\:\\Users\\Noah\\Zotero\\storage\\JC59IDFK\\Karypis - 2000 - Application of dimensionality reduction in recommender system-a case study.pdf;C\:\\Users\\Noah\\Zotero\\storage\\3E4PKQFR\\Application_of_dimensionality_reduction_in_recommender_system_a_case_study.html}
}

@article{korenMatrixFactorizationTechniques2009,
  title = {Matrix {{Factorization Techniques}} for {{Recommender Systems}}},
  author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
  date = {2009-08-01},
  journaltitle = {Computer},
  volume = {42},
  number = {8},
  pages = {30--37},
  issn = {0018-9162},
  doi = {10.1109/MC.2009.263},
  url = {https://doi.org/10.1109/MC.2009.263},
  urldate = {2025-03-14},
  abstract = {As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest-neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.},
  file = {C:\Users\Noah\Zotero\storage\RHJQ7E27\koren_matrix.pdf}
}

@book{leskovecMiningMassiveDatasets2020,
  title = {Mining of {{Massive Datasets}}},
  author = {Leskovec, Jure and Rajaraman, Anand and Ullman, Jeffrey D},
  date = {2020},
  edition = {3},
  publisher = {Cambridge University Press},
  langid = {english},
  file = {C:\Users\Noah\Zotero\storage\SUSBWDIC\Leskovec et al. - Mining of Massive Datasets.pdf}
}

@article{martinExtraordinarySVD2012,
  entrysubtype = {magazine},
  title = {The {{Extraordinary SVD}}},
  author = {Martin, Carla D. and Porter, Mason A.},
  date = {2012-03-11},
  journaltitle = {The American Mathematical Monthly},
  volume = {119},
  number = {10},
  eprint = {1103.2338},
  eprinttype = {arXiv},
  eprintclass = {math},
  pages = {838--851},
  url = {http://arxiv.org/abs/1103.2338},
  urldate = {2025-03-23},
  abstract = {The singular value decomposition (SVD) is a popular matrix factorization that has been used widely in applications ever since an efficient algorithm for its computation was developed in the 1970s. In recent years, the SVD has become even more prominent due to a surge in applications and increased computational memory and speed. To illustrate the vitality of the SVD in data analysis, we highlight three of its lesser-known yet fascinating applications: the SVD can be used to characterize political positions of Congressmen, measure the growth rate of crystals in igneous rock, and examine entanglement in quantum computation. We also discuss higher-dimensional generalizations of the SVD, which have become increasingly crucial with the newfound wealth of multidimensional data and have launched new research initiatives in both theoretical and applied mathematics. With its bountiful theory and applications, the SVD is truly extraordinary.},
  keywords = {Computer Science - Numerical Analysis,Mathematics - Numerical Analysis,Physics - Computational Physics,Physics - Data Analysis Statistics and Probability},
  file = {C\:\\Users\\Noah\\Zotero\\storage\\4FJ5ZCN4\\Martin und Porter - 2012 - The Extraordinary SVD.pdf;C\:\\Users\\Noah\\Zotero\\storage\\FN47X4ZX\\1103.html}
}

@misc{ngMachineLearningCS2292023,
  title = {Machine {{Learning}}. {{CS229 Lecture Notes}}.},
  author = {Ng, Andrew and Ma, Tengyu},
  date = {2023},
  url = {https://cs229.stanford.edu/main_notes.pdf},
  urldate = {2025-02-23},
  organization = {Stanford University},
  file = {C:\Users\Noah\Zotero\storage\P6XQ2PB8\main_notes.pdf}
}

@article{nikolakopoulosEigenRecGeneralizingPureSVD2019,
  title = {{{EigenRec}}: {{Generalizing PureSVD}} for {{Effective}} and {{Efficient Top-N Recommendations}}},
  shorttitle = {{{EigenRec}}},
  author = {Nikolakopoulos, Athanasios N. and Kalantzis, Vassilis and Gallopoulos, Efstratios and Garofalakis, John D.},
  date = {2019-01},
  journaltitle = {Knowledge and Information Systems},
  shortjournal = {Knowl Inf Syst},
  volume = {58},
  number = {1},
  eprint = {1511.06033},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {59--81},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-018-1197-7},
  url = {https://link.springer.com/article/10.1007/s10115-018-1197-7},
  urldate = {2025-03-13},
  abstract = {We introduce EigenRec; a versatile and efficient Latent-Factor framework for Top-N Recommendations that includes the well-known PureSVD algorithm as a special case. EigenRec builds a low dimensional model of an inter-item proximity matrix that combines a similarity component, with a scaling operator, designed to control the influence of the prior item popularity on the final model. Seeing PureSVD within our framework provides intuition about its inner workings, exposes its inherent limitations, and also, paves the path towards painlessly improving its recommendation performance. A comprehensive set of experiments on the MovieLens and the Yahoo datasets based on widely applied performance metrics, indicate that EigenRec outperforms several state-of-the-art algorithms, in terms of Standard and Long-Tail recommendation accuracy, exhibiting low susceptibility to sparsity, even in its most extreme manifestations -- the Cold-Start problems. At the same time EigenRec has an attractive computational profile and it can apply readily in large-scale recommendation settings.},
  keywords = {Computer Science - Databases,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Information Retrieval,Computer Science - Numerical Analysis,Computer Science - Social and Information Networks},
  file = {C\:\\Users\\Noah\\Zotero\\storage\\UW6QA6LF\\s10115-018-1197-7.pdf;C\:\\Users\\Noah\\Zotero\\storage\\J4BYGYFL\\1511.html}
}

@online{proof:SpectralTom,
  title = {Oxford {{Linear Algebra}}: {{Spectral Theorem Proof}}},
  shorttitle = {Oxford {{Linear Algebra}}},
  author = {Crawford, Tom},
  date = {2022},
  url = {https://tomrocksmaths.com/2022/11/18/oxford-linear-algebra-spectral-theorem-proof/},
  urldate = {2025-01-02},
  abstract = {University of Oxford mathematician Dr Tom Crawford goes through a full proof of the Spectral Theorem. Check out ProPrep with a 30-day free trial to see how it can help you to improve your performan…},
  langid = {english},
  file = {C:\Users\Noah\Zotero\storage\72WFX4AK\oxford-linear-algebra-spectral-theorem-proof.html}
}

@misc{raschLineareAlgebraVersion2021,
  title = {Lineare {{Algebra}} ({{Version}} 3. 3. 2)},
  author = {Räsch, Thoralf},
  date = {2021},
  url = {https://www.math.uni-bonn.de/people/raesch/Papers_and_Notes/ThR_LA_Skript.pdf},
  urldate = {2025-01-02},
  organization = {Universität Bonn},
  file = {C:\Users\Noah\Zotero\storage\HFFX5PBE\ThR_LA_Skript.pdf}
}

@online{SpectralTheoremBrilliant,
  title = {Spectral {{Theorem}} | {{Brilliant Math}} \& {{Science Wiki}}},
  url = {https://brilliant.org/wiki/spectral-theorem/},
  urldate = {2024-12-26},
  abstract = {In linear algebra, one is often interested in the canonical forms of a linear transformation. Given a particularly nice basis for the vector spaces in which one is working, the matrix of a linear transformation may also be particularly nice, revealing some information about how the transformation operates on the vector space. The spectral theorem provides a sufficient criterion for the existence of a particular canonical form. Specifically, the spectral theorem states that …},
  langid = {american},
  file = {C:\Users\Noah\Zotero\storage\EY3BGL6U\spectral-theorem.html}
}

@book{strangIntroductionLinearAlgebra2009,
  title = {Introduction to {{Linear Algebra}}},
  author = {Strang, Gilbert},
  date = {2009},
  edition = {4},
  publisher = {Wellesley - Cambridge Press},
  location = {Wellesley},
  langid = {english},
  file = {C:\Users\Noah\Zotero\storage\8JILSLEU\Strang - Introduction to Linear Algebra, 4th Edition.pdf}
}

@book{strangLineareAlgebra2003,
  title = {Lineare {{Algebra}}},
  author = {Strang, Gilbert},
  date = {2003},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-55631-9},
  url = {http://link.springer.com/10.1007/978-3-642-55631-9},
  urldate = {2025-01-23},
  isbn = {978-3-540-43949-3 978-3-642-55631-9},
  keywords = {Elektrotechnik,Fourier-Reihe,Fourier-Transformation,komplexe Zahl,lineare Gleichung,lineare Optimierung,Markov,matrix theory,Matrizen,Permutation,Programmierung,Schnelle Fouriertransformation,Transformation,Vektor,Vektorraum,Vektorrechnung},
  file = {C:\Users\Noah\Zotero\storage\XARWRKBJ\Strang - 2003 - Lineare Algebra.pdf}
}

@book{tseFundamentalsWirelessCommunication2005,
  title = {Fundamentals of {{Wireless Communication}}},
  author = {Tse, David and Viswanath, Pramod},
  date = {2005},
  publisher = {Cambridge University Press},
  url = {https://stanford.edu/~dntse/wireless_book.html},
  urldate = {2025-03-26},
  file = {C:\Users\Noah\Zotero\storage\P9LMR5UI\wireless_book.html}
}

@misc{zhangLinearAlgebraData2022,
  title = {Linear {{Algebra}} for {{Data Science}}. {{Lecture}} 4. {{Singular}} Value Decomposition ({{SVD}})},
  author = {Zhang, Zecheng},
  date = {2022},
  url = {https://www.math.cmu.edu/users/zechengz/fall_2022_la/lec4_2p.pdf},
  urldate = {2025-03-07},
  langid = {english},
  organization = {Carnegie Mellon University},
  file = {C:\Users\Noah\Zotero\storage\PP4LNKKC\Zhang - Singular value decomposition (SVD).pdf}
}
